{"cells":[{"cell_type":"code","source":["from pyspark import SparkContext, SparkConf\nfrom pyspark.sql.types import *\nfrom pyspark.mllib.util import Vectors, MLUtils\nfrom pyspark.mllib.linalg import VectorUDT\nfrom pyspark.sql.functions import UserDefinedFunction\nfrom pyspark.sql.types import DataType, StringType"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"47117e7b-fa1e-440b-8112-7f48fc927992"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def read_csv(path):\n    df = spark.read.csv(path, header=True, inferSchema=True)\n    \n    udf = UserDefinedFunction(lambda x: Vectors.parse(x), VectorUDT())\n    # https://spark.apache.org/docs/latest/ml-migration-guides.html\n    new_df = MLUtils.convertVectorColumnsToML(df.withColumn('features', udf(df.features)))\n    \n    return new_df"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a4369215-e7f0-4422-85b2-bcfc5f61e741"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.mllib.evaluation import MulticlassMetrics\nfrom pyspark.sql.types import StringType, IntegerType\nimport pyspark.sql.functions as F\nimport numpy as np\nconcat_udf = F.udf(lambda cols: float(int(\"\".join([str(int(x)) for x in cols]), 2)), DoubleType())\n\ndef evaluate(df, labelCols, gettopX=-1, getfirstX=-1):\n    labelCols2 = [i+\"_pred\" for i in labelCols]\n    df.cache()\n    \n    r_list = {i: np.zeros((len(labelCols))) for i in ['accuracy', 'precision', 'recall', 'fmeasure']}\n    for i in xrange(len(labelCols)):\n        predandlabels = df.select(labelCols2[i], labelCols[i]).rdd \\\n                        .map(lambda x: (float(x[labelCols2[i]]), float(x[labelCols[i]])))\n        metrics = MulticlassMetrics(predandlabels)\n\n        # print metrics.confusionMatrix()\n        r_list['accuracy'][i] = metrics.accuracy\n        r_list['precision'][i] = metrics.precision(1.0)\n        r_list['recall'][i] = metrics.recall(1.0)\n        r_list['fmeasure'][i] = metrics.fMeasure(label=1.0)\n\n    results = {}\n    for m, rs in r_list.iteritems():\n        results[m] = np.mean(rs)\n        \n    for code, num in [('top', gettopX), ('first', getfirstX)]:\n        if num <= 0: continue\n        \n        if code == 'top':\n            idx = np.argsort(np.nan_to_num(r_list['fmeasure']))[-num:]\n        elif code == 'first':\n            idx = xrange(num)\n        \n        for m, rs in r_list.iteritems():\n            results['{0}_{1}'.format(m, code)] = np.mean(rs[idx])\n            \n    return results\n\ndef evaluate_em(df, labelCols, metrics=[\"f1\", \"weightedPrecision\", \"weightedRecall\", \"accuracy\"]):\n    evaluator = MulticlassClassificationEvaluator()\n    labelCols2 = [i+\"_pred\" for i in labelCols]\n    df2 = df.withColumn(\"_label\", concat_udf(F.array(labelCols)))\n    df2 = df2.withColumn(\"_pred\", concat_udf(F.array(labelCols2)))\n    \n    output = {}\n    for m in metrics:\n        result = evaluator.evaluate(df2, {evaluator.metricName: m,\n                                         evaluator.predictionCol: \"_pred\",\n                                         evaluator.labelCol: \"_label\"})\n        output[m] = result\n        \n    return output"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3d90ede6-46c1-4a07-951d-abed86e43a73"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\n\nclass CustomLogisticRegression:\n    def __init__(self):\n        pass\n    \n    def fit(self, df, maxIter=100, regParam=0.0, featuresCol=\"features\", ignoreCols=[\"id\"]):\n        self.featuresCol = featuresCol\n        self.labelCols = df.columns\n        self.labelCols.remove(\"features\")\n        for c in ignoreCols:\n            self.labelCols.remove(c)\n        self.models = []\n        \n        for c in self.labelCols:\n            lr = LogisticRegression(featuresCol=featuresCol,\n                                    labelCol=c,\n                                    predictionCol=c+\"_pred\",\n                                    probabilityCol=c+\"_prob\",\n                                    rawPredictionCol=c+\"_rpred\",\n                                    maxIter=maxIter,\n                                    regParam=regParam,\n                                    family=\"binomial\")\n            model = lr.fit(df)\n            self.models.append(model)\n            \n    def predict(self, df):\n        df_out = df\n        for c, m in zip(self.labelCols, self.models):\n            df_out = m.transform(df_out)\n            \n        return df_out"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4f5264cd-965b-40ea-836c-59bfcb07a29a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def run_experiment(input_name, iterations=[5, 10, 25, 50, 75, 100], gettopX=-1, getfirstX=-1):\n    df_train = read_csv(\"{0}_train.csv\".format(input_name))\n    df_val = read_csv(\"{0}_val.csv\".format(input_name))\n    df_test = read_csv(\"{0}_test.csv\".format(input_name))\n\n    #df_train = df_train.union(df_val)\n    \n    df_train.cache()\n    df_test.cache()\n    \n    print(input_name)\n    print(\"Train, Test:\", df_train.count(), df_test.count())\n    print(\"iter & train prec & recall & f1 & accuracy & em & test prec & recall & f1 & accuracy & em\")\n    for maxIter in iterations:\n        clr = CustomLogisticRegression()\n        clr.fit(df_train, maxIter=maxIter)\n        df_pred_train = clr.predict(df_train)\n        df_pred_test = clr.predict(df_test)\n\n        r1 = evaluate(df_pred_train, clr.labelCols, gettopX=gettopX, getfirstX=getfirstX)\n        r2 = evaluate(df_pred_test, clr.labelCols, gettopX=gettopX, getfirstX=getfirstX)\n        r3 = evaluate_em(df_pred_train, clr.labelCols, metrics=[\"accuracy\"])\n        r4 = evaluate_em(df_pred_test, clr.labelCols, metrics=[\"accuracy\"])\n        \n        print(print_latex(maxIter, r1, r2, r3, r4))\n        if gettopX > 0:\n            print(print_latex2(str(maxIter)+\" top\", r1, r2))\n        if getfirstX > 0:\n            print(print_latex3(str(maxIter)+\" first\", r1, r2))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3b0e8459-2096-4a72-8fec-fb986b259a58"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["run_experiment(\"/dbfs/FileStore/output2/DATA_WORD2VECV1_HADM_TOP10\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"84974fb5-cb03-4a18-9591-635d53089549"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2029430892429892&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>run_experiment<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;/dbfs/FileStore/output2/DATA_WORD2VECV1_HADM_TOP10&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">&lt;command-2029430892429891&gt;</span> in <span class=\"ansi-cyan-fg\">run_experiment</span><span class=\"ansi-blue-fg\">(input_name, iterations, gettopX, getfirstX)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-green-fg\">def</span> run_experiment<span class=\"ansi-blue-fg\">(</span>input_name<span class=\"ansi-blue-fg\">,</span> iterations<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">5</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">10</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">25</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">50</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">75</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">100</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> gettopX<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">-</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">,</span> getfirstX<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">-</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\">     </span>df_train <span class=\"ansi-blue-fg\">=</span> read_csv<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;{0}_train.csv&#34;</span><span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>input_name<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>     df_val <span class=\"ansi-blue-fg\">=</span> read_csv<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;{0}_val.csv&#34;</span><span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>input_name<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>     df_test <span class=\"ansi-blue-fg\">=</span> read_csv<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;{0}_test.csv&#34;</span><span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>input_name<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> \n\n<span class=\"ansi-green-fg\">&lt;command-2029430892429888&gt;</span> in <span class=\"ansi-cyan-fg\">read_csv</span><span class=\"ansi-blue-fg\">(path)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>     udf <span class=\"ansi-blue-fg\">=</span> UserDefinedFunction<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-green-fg\">lambda</span> x<span class=\"ansi-blue-fg\">:</span> Vectors<span class=\"ansi-blue-fg\">.</span>parse<span class=\"ansi-blue-fg\">(</span>x<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> VectorUDT<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>     <span class=\"ansi-red-fg\"># https://spark.apache.org/docs/latest/ml-migration-guides.html</span>\n<span class=\"ansi-green-fg\">----&gt; 6</span><span class=\"ansi-red-fg\">     </span>new_df <span class=\"ansi-blue-fg\">=</span> MLUtils<span class=\"ansi-blue-fg\">.</span>convertVectorColumnsToML<span class=\"ansi-blue-fg\">(</span>df<span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;features&#39;</span><span class=\"ansi-blue-fg\">,</span> udf<span class=\"ansi-blue-fg\">(</span>df<span class=\"ansi-blue-fg\">.</span>features<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      7</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      8</span>     <span class=\"ansi-green-fg\">return</span> new_df\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">__getattr__</span><span class=\"ansi-blue-fg\">(self, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1798</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">   1799</span>         <span class=\"ansi-green-fg\">if</span> name <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">in</span> self<span class=\"ansi-blue-fg\">.</span>columns<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1800</span><span class=\"ansi-red-fg\">             raise AttributeError(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1801</span>                 &#34;&#39;%s&#39; object has no attribute &#39;%s&#39;&#34; % (self.__class__.__name__, name))\n<span class=\"ansi-green-intense-fg ansi-bold\">   1802</span>         jc <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>apply<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">AttributeError</span>: &#39;DataFrame&#39; object has no attribute &#39;features&#39;</div>","errorSummary":"<span class=\"ansi-red-fg\">AttributeError</span>: &#39;DataFrame&#39; object has no attribute &#39;features&#39;","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2029430892429892&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>run_experiment<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;/dbfs/FileStore/output2/DATA_WORD2VECV1_HADM_TOP10&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">&lt;command-2029430892429891&gt;</span> in <span class=\"ansi-cyan-fg\">run_experiment</span><span class=\"ansi-blue-fg\">(input_name, iterations, gettopX, getfirstX)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-green-fg\">def</span> run_experiment<span class=\"ansi-blue-fg\">(</span>input_name<span class=\"ansi-blue-fg\">,</span> iterations<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">5</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">10</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">25</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">50</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">75</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">100</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> gettopX<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">-</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">,</span> getfirstX<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">-</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\">     </span>df_train <span class=\"ansi-blue-fg\">=</span> read_csv<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;{0}_train.csv&#34;</span><span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>input_name<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>     df_val <span class=\"ansi-blue-fg\">=</span> read_csv<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;{0}_val.csv&#34;</span><span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>input_name<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>     df_test <span class=\"ansi-blue-fg\">=</span> read_csv<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;{0}_test.csv&#34;</span><span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>input_name<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> \n\n<span class=\"ansi-green-fg\">&lt;command-2029430892429888&gt;</span> in <span class=\"ansi-cyan-fg\">read_csv</span><span class=\"ansi-blue-fg\">(path)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>     udf <span class=\"ansi-blue-fg\">=</span> UserDefinedFunction<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-green-fg\">lambda</span> x<span class=\"ansi-blue-fg\">:</span> Vectors<span class=\"ansi-blue-fg\">.</span>parse<span class=\"ansi-blue-fg\">(</span>x<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> VectorUDT<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>     <span class=\"ansi-red-fg\"># https://spark.apache.org/docs/latest/ml-migration-guides.html</span>\n<span class=\"ansi-green-fg\">----&gt; 6</span><span class=\"ansi-red-fg\">     </span>new_df <span class=\"ansi-blue-fg\">=</span> MLUtils<span class=\"ansi-blue-fg\">.</span>convertVectorColumnsToML<span class=\"ansi-blue-fg\">(</span>df<span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;features&#39;</span><span class=\"ansi-blue-fg\">,</span> udf<span class=\"ansi-blue-fg\">(</span>df<span class=\"ansi-blue-fg\">.</span>features<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      7</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      8</span>     <span class=\"ansi-green-fg\">return</span> new_df\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">__getattr__</span><span class=\"ansi-blue-fg\">(self, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1798</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">   1799</span>         <span class=\"ansi-green-fg\">if</span> name <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">in</span> self<span class=\"ansi-blue-fg\">.</span>columns<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1800</span><span class=\"ansi-red-fg\">             raise AttributeError(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1801</span>                 &#34;&#39;%s&#39; object has no attribute &#39;%s&#39;&#34; % (self.__class__.__name__, name))\n<span class=\"ansi-green-intense-fg ansi-bold\">   1802</span>         jc <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>apply<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">AttributeError</span>: &#39;DataFrame&#39; object has no attribute &#39;features&#39;</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"38e942a9-50be-4852-a3f9-edfcf734b514"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ml_baseline","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2029430892429886}},"nbformat":4,"nbformat_minor":0}
